{
    "collab_server" : "",
    "contents" : "#' Scrape meta-data from all the articles of a journal hosted on Scielo\n#'\n#' \\code{get_journal()} scrapes meta-data information of a journal hosted on Scielo.\n#'\n#' @param id_journal a character vector with the ID of the journal hosted on Scielo (the \\code{get_id_journal} function can be used to find the journal ID from its url).\n#'\n#' @importFrom magrittr \"%>%\"\n#' @export\n#'\n#' @return The function returns an object of class \\code{Scielo, data.frame} with the following variables:\n#'\n#' \\itemize{\n#'   \\item author: Author name.\n#'   \\item title: Article title.\n#'   \\item year: Year of publication.\n#'   \\item journal: Journal name.\n#'   \\item volume: Volume.\n#'   \\item number: Number.\n#'   \\item first_page: Article's first page.\n#'   \\item last_page: Article's last page\n#'   \\item abstratc: Article's abstract.\n#'   \\item keywords: Article's keywords.\n#'   \\item doi: DOI.\n#'   \\item n_authors: Number of authors.\n#'   \\item n_pages: Number of pages.\n#' }\n#'\n#' @details This functions scrapes several meta-data information, such as author's names, articles' titles, year of publication, edition and number of pages, that can be summarized with specific \\code{summary} method.\n#'\n#' @examples\n#' \\dontrun{\n#' df <- get_journal(id_journal = \"1981-3821\")\n#' summary(df)\n#' }\n\nget_journal <- function(id_journal){\n\n\n  if(!is.character(id_journal) | nchar(id_journal) != 9) stop(\"Invalid 'id_journal'.\")\n\n  scielo_data <- get_links(id_journal) %>%\n    lapply(get_xml_article) %>%\n    do.call(\"rbind\", .)\n\n  cat(\"\\n\\nDone.\\n\\n\")\n\n  class(scielo_data) <- c(\"Scielo\", \"data.frame\")\n  scielo_data\n}\n\n\n\n# Function to extract the XML links for each article in a journal\nget_links <- function(id_journal){\n\n\n  page <- sprintf(\"http://www.scielo.br/scielo.php?script=sci_issues&pid=%s&lng=en&nrm=iso\", id_journal) %>%\n    rvest::html_session()\n\n  if(httr::status_code(page) != 200) stop(\"Journal not found.\")\n\n  journal <- rvest::html_nodes(page, \"center .nomodel\") %>%\n    rvest::html_text()\n  cat(sprintf(\"\\n\\nScraping articles from: \\n\\n\\n\\t%s\\n\\n\\n...\", journal))\n\n  editions <- page %>%\n    rvest::html_nodes(\"b a\") %>%\n    rvest::html_attr(\"href\")\n\n  get_internal <- function(editions){\n    links <- xml2::read_html(editions) %>%\n      rvest::html_nodes(\".content div a\") %>%\n      rvest::html_attr(\"href\")\n    links[grepl(\"sci_arttext\", links)]\n  }\n\n  lapply(editions, get_internal) %>%\n    unlist() %>%\n    substr(56, 78) %>%\n    sprintf(\"http://www.scielo.br/scieloOrg/php/articleXML.php?pid=%s&lang=en\", .)\n}\n\n\n\n# Function to extract meta-data from an article\nget_xml_article <- function(link) {\n\n\n  page <- try(xml2::read_xml(link), silent = T)\n  if(class(page)[1] == \"try-error\") return(rep(NA, 13))\n\n  lastname <- extract_node(page, \"//article-meta/contrib-group/contrib/name/surname\")\n  firstname <- extract_node(page, \"//article-meta/contrib-group/contrib/name/given-names\")\n  title <- extract_node(page, \"//article-meta/title-group/article-title\")\n  year <- extract_node(page, \"//article-meta/pub-date/year\")\n  journal <- extract_node(page, \"//journal-title\")\n  volume <- extract_node(page, \"//article-meta/volume\")\n  number <- extract_node(page, \"//article-meta/numero\")\n  abstract <- extract_node(page, \"//article-meta/abstract/p\")\n  keywords <- extract_node(page, \"//article-meta/kwd-group/kwd\")\n  doi <- extract_node(page, \"//article-meta/article-id[@pub-id-type = 'doi']\")\n  f_pag <- extract_node(page, \"//article-meta/fpage\") %>% as.numeric()\n  l_pag <- extract_node(page, \"//article-meta/lpage\") %>% as.numeric()\n\n  res <- data.frame(author = paste(firstname, lastname, collapse = \"; \") %>% utf8(),\n                    title = utf8(title[1]),\n                    year = year[1],\n                    journal = utf8(journal),\n                    volume = volume,\n                    number = number,\n                    first_page = f_pag,\n                    last_page = l_pag,\n                    abstract = utf8(abstract[1]),\n                    keywords = paste(keywords, collapse = \"; \") %>% utf8(),\n                    doi = doi,\n                    n_authors = length(firstname),\n                    n_pages = l_pag - f_pag,\n                    stringsAsFactors = F)\n\n  res\n}\n\n\n\n# @S3 summary\n#' @export\nsummary.Scielo <- function(object, ...) {\n\n\n  journal <- as.character(object$journal[1])\n  total <- nrow(object)\n  total_articles <- nrow(object[nchar(as.character(object$abstract)) > 1,])\n  years <- range(as.numeric(as.character(object$year)), na.rm = T)\n  mean_authors <- round(mean(object$n_authors[nchar(as.character(object$abstract)) > 1], na.rm = T), 2)\n  mean_size <- round(mean(object$n_pages[nchar(as.character(object$abstract)) > 1], na.rm = T), 2)\n\n  out <- list(journal = journal,\n              total = total,\n              total_articles = total_articles,\n              years = years,\n              mean_authors = mean_authors,\n              mean_size = mean_size\n  )\n\n  class(out) <- \"summary.Scielo\"\n  out\n}\n\n\n\n# @S3 print\n#' @export\nprint.summary.Scielo <- function(x, ...){\n\n\n  cat(sprintf(\"\\n### JOURNAL SUMMARY: %s (%s - %s)\\n\\n\\n\", x$journal, x$years[1], x$years[2]))\n\n  cat(\"\\tTotal number of articles: \", x$total,\n      \"\\n\\tTotal number of articles (reviews excluded): \", x$total_articles)\n\n  cat(\"\\n\\n\\tMean number of authors per article: \", x$mean_authors,\n      \"\\n\\tMean number of pages per article: \", x$mean_size, \"\\n\\n\")\n}\n",
    "created" : 1471525469466.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3803696031",
    "id" : "88509658",
    "lastKnownWriteTime" : 1471528927,
    "last_content_update" : 1471528927008,
    "path" : "~/GitHub/rScielo/R/get_journal.R",
    "project_path" : "R/get_journal.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}